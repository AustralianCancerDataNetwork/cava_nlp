{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"cava_nlp","text":"<p><code>cava_nlp</code> is a spaCy pipeline designed for real-world clinical text, with a specific focus on cancer-specific text: pathology reports, progress notes,  registry extracts, and free-text fields shaped by clinical workflows rather than linguistic norms.</p> <p>It prioritises:</p> <ul> <li>notation-heavy (e.g. <code>mg/kg</code>, <code>10^9</code>, <code>ECOG 1</code>)</li> <li>inconsistently spaced or punctuated</li> <li>rich in abbreviations and symbols</li> <li>structured meaning across critical token types (e.g. dates, dosages, measurements)</li> </ul>"},{"location":"#1-create-a-cava-pipeline","title":"1. Create a CaVa pipeline","text":"<p><code>cava_nlp</code> pipelines are constructed explicitly and do not rely on pretrained language models.</p> <pre><code>from cava_nlp import CaVaLang\n\nnlp = CaVaLang()\n</code></pre> <p>Out of the box, this provides:</p> <ul> <li>deterministic clinical tokenisation</li> <li>whitespace normalisation</li> <li>email masking prior to tokenisation</li> <li>medSpaCy sentence splitting</li> </ul> <pre><code>doc = nlp(\"Email me at test@example.com\")\n\ndoc.text\n# \"Email me at xxxxxxxxxxxxxxx\"\n</code></pre> <p>The original structure of the text is preserved while protecting tokenisation and downstream rules from incidental artefacts.</p>"},{"location":"#2-add-clinical-normalisation","title":"2. Add clinical normalisation","text":"<p>Clinical text often expresses structured meaning across multiple tokens (e.g. decimals, dates, units). The clinical normaliser merges these spans and assigns canonical forms.</p> <pre><code>nlp.add_pipe(\"clinical_normalizer\", first=True)\n\ndoc = nlp(\"Temp is 36.9 today\")\n</code></pre> <p>Inspecting tokens:</p> <pre><code>for t in doc:\n    print(t.text, t.norm_, t._.kind, t._.value)\n</code></pre> <p>Example output:</p> <pre><code>Temp Temp None None\nis is None None\n36.9 36.9 decimal 36.9\ntoday today None None\n</code></pre> <p>Key points:</p> <ul> <li>spans may be merged into single tokens</li> <li><code>token.norm_</code> provides the canonical representation</li> <li>structured values are stored on token extensions</li> <li>the original text remains intact</li> </ul>"},{"location":"#3-normalisation-produces-span-groups","title":"3. Normalisation produces span groups","text":"<p>Normalised tokens are grouped automatically:</p> <pre><code>doc.spans.keys()\n# dict_keys(['decimal', 'date', 'time', 'unit_norm', ...])\n</code></pre> <p>These span groups allow downstream components to reason over normalised clinical concepts without re-parsing raw text.</p>"},{"location":"#4-add-a-rule-engine","title":"4. Add a rule engine","text":"<p>Rule engines layer domain-specific meaning on top of normalisation. Each engine is added independently.</p> <pre><code>nlp.add_pipe(\n    \"rule_engine\",\n    name=\"ecog_value\",\n    config={\n        \"engine_config_path\": None,\n        \"component_name\": \"ecog_status\",\n    },\n)\n</code></pre> <p>Processing text:</p> <pre><code>doc = nlp(\"ECOG 1\")\n</code></pre> <p>Results:</p> <pre><code>[(ent.text, ent.label_) for ent in doc.ents]\n# [('ECOG 1', 'ecog_status')]```\n\nStructured values are available via span attributes:\n\n```python\ndoc.spans[\"ecog_status\"][0]._.value\n# 1\n</code></pre> <p>Rule engines support:</p> <ul> <li>value extraction and aggregation</li> <li>exclusions and fallbacks</li> <li>literal or computed assignments</li> <li>emission of both entities and span groups</li> </ul>"},{"location":"#relevant-contributions","title":"Relevant contributions","text":"<ol> <li> <p>Tokenisation    Clinical-oriented, deterministic, and explicit.</p> </li> <li> <p>Normalisation    Merge spans, assign canonical forms, attach structure.</p> </li> <li> <p>Rule engines    Map patterns to domain meaning and values based on configuration definitions.</p> </li> </ol>"},{"location":"getting-started/","title":"Getting started","text":""},{"location":"getting-started/#install","title":"Install","text":"<pre><code>pip install cava_nlp\n</code></pre>"},{"location":"getting-started/#create-an-nlp-pipeline","title":"Create an NLP pipeline","text":"<pre><code>from cava_nlp.language import CaVaLang\nn = CaVaLang()\nn.add_pipe(\"clinical_normalizer\", first=True)\nn.add_pipe(\"rule_engine\", name=\"ecog_value\", config={...})\ndoc = n(\"The patient's ECOG score is 2.\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_, ent._.normalisation)\n</code></pre>"},{"location":"reference/","title":"Reference","text":"<p>API reference generated from docstrings via mkdocstrings.</p>"},{"location":"reference/language/","title":"cava_nlp.language","text":""},{"location":"reference/language/#cava_nlp.language.CaVaLang","title":"CaVaLang","text":"<pre><code>CaVaLang(with_section_context: bool = False, with_dated_section_context: bool = False, *args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>English</code></p>"},{"location":"reference/normaliser/","title":"cava_nlp.normalisation.normaliser","text":""},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.NormalisationResult","title":"NormalisationResult  <code>dataclass</code>","text":"<pre><code>NormalisationResult(norm: str, attrs: Dict[str, Any] = dict())\n</code></pre> <p>Structured output returned by all normaliser <code>compute()</code> methods.</p> <p>Attributes:</p> Name Type Description <code>norm</code> <code>str</code> <p>The canonical string representation assigned as the token's <code>NORM</code>  attribute after merging. This replaces <code>token.norm_</code> for the merged span, enabling downstream components to work with a consistent, normalised textual representation (e.g., \"5.4\", \"10^9\", \"2024-01-03\").</p> <code>attrs</code> <code>Dict[str, Any]</code> <p>A mapping of token extension names to values. These are written directly  into the merged token using::</p> <pre><code>setattr(token._, ext_name, value)\n</code></pre> <p>Examples include: - kind=\"decimal\" - value=5.4 - unit=\"kg\" - date_obj=datetime(...)</p> <p>Because attrs is a free-form dictionary, each normaliser can specify  arbitrary structured metadata relevant to its domain.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.BaseNormalizer","title":"BaseNormalizer","text":"<pre><code>BaseNormalizer(nlp)\n</code></pre> <p>Defines the interface and processing flow used by normalisation components. </p> <p>Each subclass implements a spaCy <code>Matcher</code> and  <code>compute()</code> method to extracts  structured information from matched spans, plus optional token-level extensions.</p> <p>Methods:</p> Name Description <code>compute</code> <p>Override to define how to normalise the matched span.</p> <code>get_spans</code> <p>Returns matched spans after filtering overlaps.</p> <code>apply</code> <p>Applies the normaliser to the document, merges spans, assigns NORM, and  populates token attributes from the compute() result.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.BaseNormalizer.compute","title":"compute","text":"<pre><code>compute(span) -&gt; NormalisationResult\n</code></pre> <p>Override in subclass</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.BaseNormalizer.apply","title":"apply","text":"<pre><code>apply(doc)\n</code></pre> <p>Run matcher on doc and merge spans.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.DecimalNormalizer","title":"DecimalNormalizer","text":"<pre><code>DecimalNormalizer(nlp)\n</code></pre> <p>               Bases: <code>BaseNormalizer</code></p> <p>This is required because of the harsh tokenization in this pipeline - otherwise would be core spaCy functionality. \"Temp is 36.9 today\"      token [\"36.9\"] norm=\"36.9\", value=36.9, kind=\"decimal\"</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.DecimalNormalizer.apply","title":"apply","text":"<pre><code>apply(doc)\n</code></pre> <p>Run matcher on doc and merge spans.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.SciNotNormalizer","title":"SciNotNormalizer","text":"<pre><code>SciNotNormalizer(nlp)\n</code></pre> <p>               Bases: <code>BaseNormalizer</code></p> <p>\"WCC was 10^9 today\"     token [\"10^9\"], norm=\"10.0^9\", value=1_000_000_000, kind=\"scientific\", base=10.0, exp=9</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.SciNotNormalizer.apply","title":"apply","text":"<pre><code>apply(doc)\n</code></pre> <p>Run matcher on doc and merge spans.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.DateNormalizer","title":"DateNormalizer","text":"<pre><code>DateNormalizer(nlp)\n</code></pre> <p>               Bases: <code>BaseNormalizer</code></p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.DateNormalizer.apply","title":"apply","text":"<pre><code>apply(doc)\n</code></pre> <p>Run matcher on doc and merge spans.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.TimeNormalizer","title":"TimeNormalizer","text":"<pre><code>TimeNormalizer(nlp)\n</code></pre> <p>               Bases: <code>BaseNormalizer</code></p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.TimeNormalizer.apply","title":"apply","text":"<pre><code>apply(doc)\n</code></pre> <p>Run matcher on doc and merge spans.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.UnitNormalizer","title":"UnitNormalizer","text":"<pre><code>UnitNormalizer(nlp)\n</code></pre> <p>               Bases: <code>BaseNormalizer</code></p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.UnitNormalizer.apply","title":"apply","text":"<pre><code>apply(doc)\n</code></pre> <p>Run matcher on doc and merge spans.</p>"},{"location":"reference/normaliser/#cava_nlp.normalisation.normaliser.ClinicalNormalizer","title":"ClinicalNormalizer","text":"<pre><code>ClinicalNormalizer(nlp)\n</code></pre>"},{"location":"reference/rule_engine/","title":"cava_nlp.rule_engine.rule_engine","text":""},{"location":"reference/rule_engine/#cava_nlp.rule_engine.rule_engine.AGGREGATORS","title":"AGGREGATORS  <code>module-attribute</code>","text":"<pre><code>AGGREGATORS: dict[str, AggregatorAny] = {'max': agg_max, 'min': agg_min, 'join': agg_join, 'first': agg_first}\n</code></pre>"},{"location":"reference/rule_engine/#cava_nlp.rule_engine.rule_engine.CASTERS","title":"CASTERS  <code>module-attribute</code>","text":"<pre><code>CASTERS: dict[str, Callable[[Any], List[Any]]] = {'int': partial(safe_cast, int), 'float': partial(safe_cast, float), 'str': partial(safe_cast, str)}\n</code></pre>"},{"location":"reference/rule_engine/#cava_nlp.rule_engine.rule_engine.RuleEngine","title":"RuleEngine","text":"<pre><code>RuleEngine(nlp: Language, name: str, config: RuleEngineConfig)\n</code></pre> <p>Generic rule engine component.</p> <p>Config (per instance):</p> <ul> <li>span_label: str                # span-group name e.g \"weight\"</li> <li>entity_label: Optional[str]    # span label, e.g. \"WEIGHT\"</li> <li>value_type: Optional[str]      # type to cast value to: \"int\", \"float\", \"str\" - defaults string</li> <li>patterns: dict                 # spaCy Matcher patterns (outer list)</li> <li>patterns.value: Optional[float|str]     # literal value to assign to matched span</li> <li>patterns.value_patterns: Optional[list] # patterns to extract numeric portion within span</li> <li>patterns.exclusions: Optional[list]     # patterns to suppress spans</li> <li>merge_ents: Optional[bool]              # whether to merge matched span into a single token</li> </ul> <p>Create a rule-based extraction component.</p> <p>Parameters:</p> Name Type Description Default <code>nlp</code> <code>Language</code> <p>The spaCy Language object. Used to access the vocabulary and to construct matchers.</p> required <code>name</code> <code>str</code> <p>Name of this rule engine instance (pipeline component name).</p> required <code>config</code> <code>Mapping[str, Any]</code> <p>Configuration dictionary, typically loaded from YAML/JSON.</p> required <code>Expected</code> required"},{"location":"reference/rule_engine/#cava_nlp.rule_engine.rule_engine.ValueResolver","title":"ValueResolver","text":"<pre><code>ValueResolver(caster: Caster[Raw, Final], aggregator: Aggregator[Final])\n</code></pre> <p>               Bases: <code>Generic[Raw, Final]</code></p> <p>Value resolution utilities for rule-based extraction.</p> <p>This module provides a small, composable framework for turning raw extracted values (usually strings or lightweight objects produced by matchers) into final, typed values suitable for downstream use.</p> <p>2-stage resolution process:</p> <ol> <li> <p>Aggregation: Combine zero or more raw values extracted from a span into a single representative raw value (e.g. max, min, first, join).</p> </li> <li> <p>Casting: Convert the aggregated raw value into a final, typed value (e.g. int, float, str), handling failures safely.</p> </li> </ol> <p>This separation allows rules to express concepts like: - \u201ctake the maximum ECOG score mentioned\u201d - \u201cjoin multiple tokens into a single string\u201d - \u201cprefer literal values over extracted ones\u201d</p> <p>without baking domain logic into the rule engine itself.</p> <p>A <code>ValueResolver</code> encapsulates the policy for turning a collection of raw values into a single, meaningful result.</p> <p>Resolution follows a strict priority order:</p> <ol> <li>Literal override \u2013 if a literal value is provided, it always wins.</li> <li>Aggregated extraction \u2013 raw values are aggregated, then cast.</li> <li>Fallback \u2013 used when no literal or extractable value is available.</li> </ol>"},{"location":"reference/rule_engine/#cava_nlp.rule_engine.rule_engine.ValueResolver.resolve","title":"resolve","text":"<pre><code>resolve(raw_values: Sequence[Raw], *, literal: Optional[Final] = None, fallback: Optional[Final] = None) -&gt; Optional[Final]\n</code></pre> <p>Decide final value:</p> <p>1) literal if provided 2) aggregated raw values if any 3) fallback if no extracted values</p>"}]}